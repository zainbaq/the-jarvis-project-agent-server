{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state models\n",
    "class DBConnection(BaseModel):\n",
    "    \"\"\"Database connection details\"\"\"\n",
    "    type: str = Field(description=\"Type of database (PostgreSQL, SQL)\")\n",
    "    connection_string: str = Field(description=\"Connection string or parameters for the database\")\n",
    "    name: str = Field(description=\"A name to identify this connection\")\n",
    "\n",
    "class SchemaInfo(BaseModel):\n",
    "    \"\"\"Information about database schema\"\"\"\n",
    "    tables: Dict[str, List[str]] = Field(default_factory=dict, description=\"Map of table names to column names\")\n",
    "    relationships: List[str] = Field(default_factory=list, description=\"Known foreign key relationships\")\n",
    "    description: str = Field(default=\"\", description=\"Human-readable description of the schema\")\n",
    "\n",
    "class DBAssistantState(BaseModel):\n",
    "    \"\"\"State for the DB Assistant agent\"\"\"\n",
    "    query: str = Field(description=\"The user's original query\")\n",
    "    connections: Dict[str, DBConnection] = Field(default_factory=dict, description=\"Available database connections\")\n",
    "    schema_info: Dict[str, SchemaInfo] = Field(default_factory=dict, description=\"Schema information for each connection\")\n",
    "    analysis_plan: Optional[List[str]] = Field(default=None, description=\"Steps to analyze and solve the query\")\n",
    "    current_step: int = Field(default=0, description=\"Current step in the analysis plan\")\n",
    "    results: List[Dict[str, Any]] = Field(default_factory=list, description=\"Results from database queries\")\n",
    "    messages: List[Any] = Field(default_factory=list, description=\"Conversation history\")\n",
    "    errors: List[str] = Field(default_factory=list, description=\"Any errors encountered\")\n",
    "    final_answer: Optional[str] = Field(default=None, description=\"Final answer to the user's query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection and schema handling\n",
    "def connect_to_db(connection: DBConnection):\n",
    "    \"\"\"Create a connection to the specified database\"\"\"\n",
    "    if connection.type.lower() == \"postgresql\":\n",
    "        return create_engine(connection.connection_string)\n",
    "    elif connection.type.lower() == \"sql\" or connection.type.lower() == \"mysql\":\n",
    "        # For general SQL databases\n",
    "        return create_engine(connection.connection_string)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported database type: {connection.type}\")\n",
    "\n",
    "def get_schema_info(engine) -> SchemaInfo:\n",
    "    \"\"\"Extract schema information from a database\"\"\"\n",
    "    inspector = inspect(engine)\n",
    "    schema_info = SchemaInfo()\n",
    "    \n",
    "    # Get all tables and their columns\n",
    "    for table_name in inspector.get_table_names():\n",
    "        columns = [column['name'] for column in inspector.get_columns(table_name)]\n",
    "        schema_info.tables[table_name] = columns\n",
    "        \n",
    "        # Get foreign key relationships\n",
    "        for fk in inspector.get_foreign_keys(table_name):\n",
    "            relationship = f\"Table '{table_name}' column '{fk['constrained_columns'][0]}' references \"\n",
    "            relationship += f\"table '{fk['referred_table']}' column '{fk['referred_columns'][0]}'\"\n",
    "            schema_info.relationships.append(relationship)\n",
    "    \n",
    "    # Create a human-readable description\n",
    "    description_parts = [\"Database schema:\"]\n",
    "    \n",
    "    for table_name, columns in schema_info.tables.items():\n",
    "        description_parts.append(f\"- Table: {table_name}\")\n",
    "        description_parts.append(f\"  Columns: {', '.join(columns)}\")\n",
    "    \n",
    "    if schema_info.relationships:\n",
    "        description_parts.append(\"\\nRelationships:\")\n",
    "        for relationship in schema_info.relationships:\n",
    "            description_parts.append(f\"- {relationship}\")\n",
    "    \n",
    "    schema_info.description = \"\\n\".join(description_parts)\n",
    "    return schema_info\n",
    "\n",
    "def execute_query(engine, query_string):\n",
    "    \"\"\"Execute a SQL query and return results\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            result = connection.execute(text(query_string))\n",
    "            # Convert to list of dictionaries\n",
    "            columns = result.keys()\n",
    "            return [dict(zip(columns, row)) for row in result.fetchall()]\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# LangGraph agent nodes\n",
    "def parse_user_input(state: DBAssistantState) -> DBAssistantState:\n",
    "    \"\"\"Parse the user input to identify the type of query and required information\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "    \n",
    "    # Prepare schema information for prompt\n",
    "    schema_context = \"\"\n",
    "    for conn_name, schema in state.schema_info.items():\n",
    "        schema_context += f\"\\n\\nConnection: {conn_name}\\n{schema.description}\"\n",
    "    \n",
    "    messages = [\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Given this user query: \"{state.query}\"\n",
    "        \n",
    "        Here is information about the available database schemas:\n",
    "        {schema_context}\n",
    "        \n",
    "        The available database connections are: {list(state.connections.keys())}\n",
    "        \n",
    "        Based on the user query and the database schemas, create a step-by-step analysis plan.\n",
    "        For each step, specify:\n",
    "        1. Which database connection to use\n",
    "        2. What information to retrieve or calculate\n",
    "        3. Which tables and columns you'll need to query\n",
    "        \n",
    "        Make your plan as efficient as possible, using appropriate joins and aggregations.\n",
    "        Format your response as a numbered list of steps, with each step clearly defined.\n",
    "        \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    # Parse the analysis plan from the LLM response\n",
    "    plan_lines = [line.strip() for line in response.content.split('\\n') if line.strip()]\n",
    "    # Filter out any non-plan lines (intro text, etc.)\n",
    "    plan = [line for line in plan_lines if line and (line.startswith(\"Step\") or line.startswith(\"-\") or line.startswith(\"*\") or \n",
    "                                                    (len(line) > 0 and line[0].isdigit() and \".\" in line[:3]))]\n",
    "    \n",
    "    return DBAssistantState(\n",
    "        **state.dict(),\n",
    "        analysis_plan=plan,\n",
    "        messages=state.messages + [HumanMessage(content=state.query), AIMessage(content=f\"I've analyzed your query and created a plan based on the database schema:\\n\\n\" + \"\\n\".join(plan))]\n",
    "    )\n",
    "\n",
    "def execute_plan_step(state: DBAssistantState) -> DBAssistantState:\n",
    "    \"\"\"Execute the current step in the analysis plan\"\"\"\n",
    "    if not state.analysis_plan or state.current_step >= len(state.analysis_plan):\n",
    "        return state\n",
    "    \n",
    "    current_step = state.analysis_plan[state.current_step]\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "    \n",
    "    # Prepare schema information for prompt\n",
    "    schema_context = \"\"\n",
    "    for conn_name, schema in state.schema_info.items():\n",
    "        schema_context += f\"\\n\\nConnection: {conn_name}\\n{schema.description}\"\n",
    "    \n",
    "    # Include previous results for context if available\n",
    "    previous_results = \"\"\n",
    "    if state.results:\n",
    "        previous_results = \"\\n\\nResults from previous steps:\\n\"\n",
    "        for i, result in enumerate(state.results):\n",
    "            previous_results += f\"Step {i+1}: {result['description']}\\n\"\n",
    "            previous_results += f\"Results: {result['result']}\\n\"\n",
    "    \n",
    "    # Use LLM to generate SQL for the current step\n",
    "    messages = [\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Based on the user query: \"{state.query}\"\n",
    "        \n",
    "        I need to execute this step in my analysis plan:\n",
    "        \"{current_step}\"\n",
    "        \n",
    "        Here is information about the available database schemas:\n",
    "        {schema_context}\n",
    "        \n",
    "        Available database connections: {list(state.connections.keys())}\n",
    "        {previous_results}\n",
    "        \n",
    "        Generate the exact SQL query needed for this step.\n",
    "        Make sure to:\n",
    "        - Use the correct table and column names from the schema\n",
    "        - Use appropriate joins if needed\n",
    "        - Use proper syntax for the database type\n",
    "        \n",
    "        Format your response as:\n",
    "        CONNECTION: [connection_name]\n",
    "        SQL: [sql_query]\n",
    "        \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Parse the SQL query and connection from the response\n",
    "    lines = response.content.split('\\n')\n",
    "    connection_name = None\n",
    "    sql_query = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"CONNECTION:\"):\n",
    "            connection_name = line.replace(\"CONNECTION:\", \"\").strip()\n",
    "        elif line.startswith(\"SQL:\"):\n",
    "            sql_query = line.replace(\"SQL:\", \"\").strip()\n",
    "        elif sql_query and line:  # For multi-line SQL\n",
    "            sql_query += \" \" + line.strip()\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    try:\n",
    "        if connection_name and connection_name in state.connections and sql_query:\n",
    "            connection = state.connections[connection_name]\n",
    "            engine = connect_to_db(connection)\n",
    "            result = execute_query(engine, sql_query)\n",
    "            \n",
    "            # Store the results\n",
    "            step_result = {\n",
    "                \"step\": state.current_step,\n",
    "                \"description\": current_step,\n",
    "                \"sql\": sql_query,\n",
    "                \"connection\": connection_name,\n",
    "                \"result\": result\n",
    "            }\n",
    "            \n",
    "            # Prepare message content\n",
    "            message_content = f\"Executed step {state.current_step + 1}:\\n{current_step}\\n\\nSQL used:\\n```sql\\n{sql_query}\\n```\\n\\nResults: {result}\"\n",
    "            \n",
    "            # Update state\n",
    "            return DBAssistantState(\n",
    "                **state.dict(),\n",
    "                current_step=state.current_step + 1,\n",
    "                results=state.results + [step_result],\n",
    "                messages=state.messages + [AIMessage(content=message_content)]\n",
    "            )\n",
    "        else:\n",
    "            error = \"Failed to extract valid connection or SQL query from LLM response.\"\n",
    "            return DBAssistantState(\n",
    "                **state.dict(),\n",
    "                errors=state.errors + [error],\n",
    "                messages=state.messages + [AIMessage(content=f\"Error in step {state.current_step + 1}: {error}\")]\n",
    "            )\n",
    "    except Exception as e:\n",
    "        error = f\"Error executing SQL: {str(e)}\"\n",
    "        return DBAssistantState(\n",
    "            **state.dict(),\n",
    "            errors=state.errors + [error],\n",
    "            messages=state.messages + [AIMessage(content=f\"Error in step {state.current_step + 1}: {error}\")]\n",
    "        )\n",
    "\n",
    "def generate_final_answer(state: DBAssistantState) -> DBAssistantState:\n",
    "    \"\"\"Generate the final answer based on all the query results\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "    \n",
    "    # Compile all results to create context for the final answer\n",
    "    results_context = \"\\n\\n\".join([\n",
    "        f\"Step {r['step'] + 1}: {r['description']}\\nSQL: {r['sql']}\\nResults: {r['result']}\"\n",
    "        for r in state.results\n",
    "    ])\n",
    "    \n",
    "    messages = [\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Based on the user query: \"{state.query}\"\n",
    "        \n",
    "        And these analysis results:\n",
    "        {results_context}\n",
    "        \n",
    "        Generate a concise, natural language answer that directly addresses the user's query.\n",
    "        Include relevant numbers and statistics when appropriate.\n",
    "        \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return DBAssistantState(\n",
    "        **state.dict(),\n",
    "        final_answer=response.content,\n",
    "        messages=state.messages + [AIMessage(content=response.content)]\n",
    "    )\n",
    "\n",
    "def should_continue_plan(state: DBAssistantState) -> str:\n",
    "    \"\"\"Determine if we should continue with the plan or move to final answer\"\"\"\n",
    "    if not state.analysis_plan:\n",
    "        return \"generate_final_answer\"\n",
    "    \n",
    "    if state.current_step < len(state.analysis_plan):\n",
    "        return \"execute_plan_step\"\n",
    "    else:\n",
    "        return \"generate_final_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "def build_db_assistant_graph():\n",
    "    \"\"\"Build the LangGraph workflow for the DB Assistant agent\"\"\"\n",
    "    graph = StateGraph(DBAssistantState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph.add_node(\"parse_user_input\", parse_user_input)\n",
    "    graph.add_node(\"execute_plan_step\", execute_plan_step)\n",
    "    graph.add_node(\"generate_final_answer\", generate_final_answer)\n",
    "    \n",
    "    # Add edges\n",
    "    graph.add_edge(\"parse_user_input\", should_continue_plan)\n",
    "    graph.add_edge(\"execute_plan_step\", should_continue_plan)\n",
    "    graph.add_edge(\"generate_final_answer\", END)\n",
    "    \n",
    "    # Set entrypoint\n",
    "    graph.set_entry_point(\"parse_user_input\")\n",
    "    \n",
    "    return graph.compile()\n",
    "\n",
    "# Main handler function\n",
    "def db_assistant(query: str, connections: List[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main function to handle a DB Assistant query\n",
    "    \n",
    "    Args:\n",
    "        query: The user's query\n",
    "        connections: List of DB connection details\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the response and any results\n",
    "    \"\"\"\n",
    "    # Process connections and get schema information\n",
    "    processed_connections = {}\n",
    "    schema_info = {}\n",
    "    \n",
    "    if connections:\n",
    "        for conn in connections:\n",
    "            db_conn = DBConnection(\n",
    "                type=conn[\"type\"],\n",
    "                connection_string=conn[\"connection_string\"],\n",
    "                name=conn[\"name\"]\n",
    "            )\n",
    "            processed_connections[conn[\"name\"]] = db_conn\n",
    "            \n",
    "            # Extract schema information\n",
    "            try:\n",
    "                engine = connect_to_db(db_conn)\n",
    "                schema_info[conn[\"name\"]] = get_schema_info(engine)\n",
    "            except Exception as e:\n",
    "                # If we can't get schema info, create an empty schema with an error note\n",
    "                schema_info[conn[\"name\"]] = SchemaInfo(\n",
    "                    description=f\"Error retrieving schema: {str(e)}\"\n",
    "                )\n",
    "    \n",
    "    # Initialize state\n",
    "    initial_state = DBAssistantState(\n",
    "        query=query,\n",
    "        connections=processed_connections,\n",
    "        schema_info=schema_info\n",
    "    )\n",
    "    \n",
    "    # Build and run the graph\n",
    "    graph = build_db_assistant_graph()\n",
    "    final_state = graph.invoke(initial_state)\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        \"answer\": final_state.final_answer,\n",
    "        \"steps\": len(final_state.analysis_plan) if final_state.analysis_plan else 0,\n",
    "        \"results\": final_state.results,\n",
    "        \"errors\": final_state.errors,\n",
    "        \"messages\": [{\"role\": m.type, \"content\": m.content} for m in final_state.messages]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge ending at unknown node `<function should_continue_plan at 0x11720ae80>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mHow many potatoes did we sell in 2024?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Run the assistant\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m result = \u001b[43mdb_assistant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mdb_assistant\u001b[39m\u001b[34m(query, connections)\u001b[39m\n\u001b[32m     57\u001b[39m initial_state = DBAssistantState(\n\u001b[32m     58\u001b[39m     query=query,\n\u001b[32m     59\u001b[39m     connections=processed_connections,\n\u001b[32m     60\u001b[39m     schema_info=schema_info\n\u001b[32m     61\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Build and run the graph\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m graph = \u001b[43mbuild_db_assistant_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m final_state = graph.invoke(initial_state)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Return results\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mbuild_db_assistant_graph\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Set entrypoint\u001b[39;00m\n\u001b[32m     17\u001b[39m graph.set_entry_point(\u001b[33m\"\u001b[39m\u001b[33mparse_user_input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/the-jarvis-project/lib/python3.11/site-packages/langgraph/graph/state.py:602\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    599\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    606\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    611\u001b[39m output_channels = (\n\u001b[32m    612\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    613\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    619\u001b[39m     ]\n\u001b[32m    620\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/the-jarvis-project/lib/python3.11/site-packages/langgraph/graph/graph.py:294\u001b[39m, in \u001b[36mGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m all_targets:\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m target != END:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge ending at unknown node `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# validate interrupts\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt:\n",
      "\u001b[31mValueError\u001b[39m: Found edge ending at unknown node `<function should_continue_plan at 0x11720ae80>`"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example connection\n",
    "    connections = [\n",
    "        {\n",
    "            \"name\": \"sales_db\",\n",
    "            \"type\": \"postgresql\",\n",
    "            \"connection_string\": \"postgresql://username:password@localhost:5432/sales_database\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Example query\n",
    "    query = \"How many potatoes did we sell in 2024?\"\n",
    "    \n",
    "    # Run the assistant\n",
    "    result = db_assistant(query, connections)\n",
    "    print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_assistant import db_assistant\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "    # Set up database connections\n",
    "    connections = [\n",
    "        {\n",
    "            \"name\": \"sales_db\",\n",
    "            \"type\": \"postgresql\",\n",
    "            \"connection_string\": f\"postgresql://{os.getenv('PG_USER')}:{os.getenv('PG_PASSWORD')}@{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}/{os.getenv('PG_DATABASE')}\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"inventory_db\",\n",
    "            \"type\": \"mysql\",\n",
    "            \"connection_string\": f\"mysql+pymysql://{os.getenv('MYSQL_USER')}:{os.getenv('MYSQL_PASSWORD')}@{os.getenv('MYSQL_HOST')}:{os.getenv('MYSQL_PORT')}/{os.getenv('MYSQL_DATABASE')}\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"customer_db\",\n",
    "            \"type\": \"postgresql\",\n",
    "            \"connection_string\": f\"postgresql://{os.getenv('PG_USER')}:{os.getenv('PG_PASSWORD')}@{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}/{os.getenv('CUSTOMER_DATABASE', 'customer_database')}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"Connecting to databases and extracting schema information...\")\n",
    "    # You could add a loading spinner here for a better user experience\n",
    "    \n",
    "    # Example queries that leverage multiple databases\n",
    "    queries = [\n",
    "        \"How many potatoes did we sell in 2024?\",\n",
    "        \"What's our best-selling product in Q1 2024?\",\n",
    "        \"Calculate the monthly sales growth percentage for 2024 so far.\",\n",
    "        \"Compare our top 5 customers by sales volume with their current inventory levels.\",\n",
    "        \"Which products are close to running out of stock based on current inventory and sales velocity?\"\n",
    "    ]\n",
    "    \n",
    "    # Run each query through the DB Assistant\n",
    "    for query in queries:\n",
    "        print(f\"\\n\\n{'='*80}\\nQUERY: {query}\\n{'='*80}\")\n",
    "        \n",
    "        result = db_assistant(query, connections)\n",
    "        \n",
    "        print(f\"\\nANSWER: {result['answer']}\")\n",
    "        print(f\"\\nSTEPS EXECUTED: {result['steps']}\")\n",
    "        \n",
    "        if result['errors']:\n",
    "            print(f\"\\nERRORS: {result['errors']}\")\n",
    "        \n",
    "        print(\"\\nRESULTS:\")\n",
    "        for i, res in enumerate(result['results']):\n",
    "            print(f\"\\nStep {i+1}: {res['description']}\")\n",
    "            print(f\"SQL: {res['sql']}\")\n",
    "            print(f\"Results: {res['result']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-jarvis-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
